{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob #used to access a file specified by a path\n",
    "import random\n",
    "import tensorflow\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "from tqdm import tqdm  #Used to print progress bars\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 #Computer Vision Library\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "data={}  #This dictionary will contain the classes as keys and a list of images belonging to that class as values\n",
    "with open('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) #to avoid taking column names\n",
    "    for row in reader:\n",
    "        #print(row[1])\n",
    "        key = row[1].lower()\n",
    "        if(key in data):\n",
    "            #print(data[key])\n",
    "            data[key].append(row[2])\n",
    "        else:\n",
    "            data[key] = [row[2]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(data.keys())\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"Master_Data\")\n",
    "os.mkdir(\"Master_Data/Training\")\n",
    "os.mkdir(\"Master_Data/Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in class_list:\n",
    "    os.mkdir(os.path.join(\"Master_Data/Training\",x))\n",
    "    os.mkdir(os.path.join(\"Master_Data/Testing\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil as sh\n",
    "split_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Code Snippet would copy 80% of the images in original input folder to the Training Folder and 20% to the Testing folder\n",
    "for clas,images in data.items():\n",
    "  train_size = int(len(images)*split_size)\n",
    "  train_images=images[:train_size]\n",
    "  test_images=images[train_size:]\n",
    "  for image in train_images:\n",
    "    source = os.path.join(\"../input/state-farm-distracted-driver-detection/imgs/train\",clas,image)\n",
    "    dest = os.path.join(\"./Master_Data/Training\",clas)\n",
    "    sh.copy(source,dest)\n",
    "  for image in test_images:\n",
    "    source = os.path.join(\"../input/state-farm-distracted-driver-detection/imgs/train\",clas,image)\n",
    "    dest = os.path.join(\"./Master_Data/Testing\",clas)\n",
    "    sh.copy(source,dest)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have Two directories, train and test under Master Data, each of which has 10 subdirectories which contain images belonging to that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset previously downloaded from Kaggle\n",
    "NUMBER_CLASSES = 10\n",
    "# Color type: 1 - grey, 3 - rgb\n",
    "\n",
    "def get_cv2_image(path, img_rows, img_cols, color_type=3):\n",
    "    # Loading as Grayscale image\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  #Converts a jpeg image to its pixel matrix\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # Reduce size\n",
    "    img = cv2.resize(img, (img_rows, img_cols)) \n",
    "    return img\n",
    "\n",
    "# Training\n",
    "def load_train(img_rows, img_cols, color_type=3):\n",
    "    train_images = [] \n",
    "    train_labels = []\n",
    "    # Loop over the training folder \n",
    "    for classed in tqdm(range(NUMBER_CLASSES)):   #prints the progress bar as well\n",
    "        print('Loading directory c{}'.format(classed))\n",
    "        files = glob(os.path.join('..', 'input', 'state-farm-distracted-driver-detection','imgs','train', 'c' + str(classed), '*.jpg')) # This will fetch all files which end with .jpg\n",
    "        for file in files:\n",
    "            img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "            train_images.append(img)\n",
    "            train_labels.append(classed)\n",
    "    return train_images, train_labels \n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type):\n",
    "    X, labels = load_train(img_rows, img_cols, color_type)\n",
    "    y = np_utils.to_categorical(labels, 10)  #Used to one hot encode the labels\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type) #reshaping (rows,cols) to (rows,cols,1) to match the CNN input\n",
    "    x_val = np.array(x_val, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 64\n",
    "img_cols = 64\n",
    "color_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "print('Train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout,BatchNormalization,MaxPooling2D\n",
    "from keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## CNN 1\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## CNN 2\n",
    "model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "## CNN 3\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(BatchNormalization(axis = 3))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "## Output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10,activation='softmax')) # We use softmax in the last layer because it convertsoutput of last layer into probability distribution\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "nb_epoch = 10\n",
    "model.fit(x_train, y_train, \n",
    "          validation_data=(x_val, y_val),\n",
    "          epochs=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing the test images\n",
    "\n",
    "test_images = [] \n",
    "test_labels = []\n",
    "# Loop over the training folder \n",
    "for classed in tqdm(range(NUMBER_CLASSES)): \n",
    "    files = glob(os.path.join('.', 'Master_Data','Testing', 'c' + str(classed), '*.jpg'))\n",
    "    for file in files:\n",
    "        img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(classed)\n",
    "\n",
    "x_test_final = test_images\n",
    "x_test_final = np.array(x_test_final, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "y_test = np_utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_final,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
